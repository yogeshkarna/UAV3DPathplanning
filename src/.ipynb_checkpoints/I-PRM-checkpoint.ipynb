{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a701ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import octomap\n",
    "import pclpy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import bbox\n",
    "import open3d as o3d\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import itertools\n",
    "\n",
    "from scipy.spatial.distance import cdist,euclidean\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fe8d71",
   "metadata": {},
   "source": [
    "## Pointcloud to Octomap conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b47d747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create octree file.\n"
     ]
    }
   ],
   "source": [
    "cloud = pclpy.pcl.PointCloud.PointXYZRGB()\n",
    "#pclpy.pcl.io.loadPCDFile('treedense1.pcd',cloud)\n",
    "#pclpy.pcl.io.loadPCDFile('/home/gyk/data/trees_globcen.pcd',cloud)\n",
    "pclpy.pcl.io.loadPCDFile('/home/gyk/data/treedense1.pcd',cloud)\n",
    "#pclpy.pcl.io.loadPCDFile('/home/gyk/data/big_env.pcd',cloud)\n",
    "\n",
    "plist=[]\n",
    "for point in cloud.points:\n",
    "    plist.append([point.x,point.y,point.z])\n",
    "parray= np.asarray(plist)\n",
    "parray.astype(float)\n",
    "\n",
    "#parameters\n",
    "resolution= 1\n",
    "origin=np.array([18, 13.5,11])#11\n",
    "\n",
    "#create octree\n",
    "tree = octomap.OcTree(resolution)\n",
    "for every in parray: \n",
    "    tree.insertPointCloud(np.asarray([every]),np.array([every[0],every[1],origin[2]]))\n",
    "    \n",
    "if tree.writeBinary(b\"/home/gyk/data/testin4.bt\"):\n",
    "    print(\"Create octree file.\")\n",
    "else:\n",
    "    print(\"Cannot create octree file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36315d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64. 51. 12.]\n"
     ]
    }
   ],
   "source": [
    "print(tree.getMetricSize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65acaba3",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4cfdb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getbbminmax(point,size):\n",
    "    return point-(size/2),point+(size/2)\n",
    "\n",
    "def b_cond(bb_min,bb_max,value):\n",
    "    X_min=bb_min[0]\n",
    "    Y_min=bb_min[1]\n",
    "    Z_min=bb_min[2]\n",
    "    X_max=bb_max[0]\n",
    "    Y_max=bb_max[1]\n",
    "    Z_max=bb_max[2]\n",
    "    X,Y,Z=value[0],value[1],value[2]\n",
    "    if X_min <= X <= X_max and Y_min <= Y <= Y_max  and Z_min <= Z <= Z_max:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def getrandomvoxels(voxeldict,val):\n",
    "    try:\n",
    "        a=random.sample(voxeldict,val)\n",
    "        return a\n",
    "    except:\n",
    "        return True\n",
    "\n",
    "def condition(coords_a,coords_b,size_a,size_b):\n",
    "    size_cond= (size_a+size_b)/2\n",
    "    count=0\n",
    "    for i in range(len(coords_a)):\n",
    "        if coords_a[i]==coords_b[i]:\n",
    "            count +=1 \n",
    "    if abs(coords_a[0]-coords_b[0]) <= size_cond:\n",
    "            if abs(coords_a[1]-coords_b[1]) <= size_cond:\n",
    "                    if abs(coords_a[2]-coords_b[2]) <= size_cond:\n",
    "                        if count==2:\n",
    "                            return True\n",
    "    return False\n",
    "        \n",
    "        \n",
    "    \n",
    "def checkconnection(a,b):\n",
    "    a_coords=a[:3]\n",
    "    b_coords=b[:3]\n",
    "    a_size=1\n",
    "    b_size=1\n",
    "    if condition(a_coords,b_coords,a_size,b_size)== True:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def removedkey(dic, key):\n",
    "    r = dict(dic)\n",
    "    del r[key]\n",
    "    return r\n",
    "\n",
    "def checking(out,childs):\n",
    "    for i in out:\n",
    "        if i not in childs:\n",
    "            return False\n",
    "    return True \n",
    "\n",
    "def errs(x,y,z,x1,y1,z1,childs):\n",
    "    fix='x'\n",
    "    if fix =='x':\n",
    "        X= np.hstack((x1,x))[np.newaxis].T\n",
    "        Y= np.hstack((y1,y))[np.newaxis].T\n",
    "        Z= np.hstack((z,z1))[np.newaxis].T\n",
    "        print(X,Y,Z)\n",
    "        out= np.hstack((X,Y,Z))\n",
    "        if not checking(out,childs):\n",
    "            return out\n",
    "        else:\n",
    "            fix='y'\n",
    "            print('checking y')\n",
    "            \n",
    "    if fix =='y':\n",
    "        X= np.hstack((x1,x))[np.newaxis].T\n",
    "        Y= np.hstack((y,y1))[np.newaxis].T\n",
    "        Z= np.hstack((z1,z))[np.newaxis].T\n",
    "        out= np.hstack((X,Y,Z))\n",
    "        if not checking(out,childs):\n",
    "            return out\n",
    "        else:\n",
    "            fix='z'\n",
    "            print('checking z')\n",
    "            \n",
    "    if fix =='z':\n",
    "        X= np.hstack((x1,x))[np.newaxis].T\n",
    "        Y= np.hstack((y1,y))[np.newaxis].T\n",
    "        Z= np.hstack((z,z1))[np.newaxis].T\n",
    "        out= np.hstack((X,Y,Z))\n",
    "        return out\n",
    "\n",
    "def join_nodes(curr, succ, childs):\n",
    "    distance= np.asarray(abs(curr-succ),dtype='uint8')\n",
    "    #pat= ['x','y','z']\n",
    "\n",
    "    x= np.linspace(curr[0]+1,succ[0],num=distance[0])\n",
    "    y= np.linspace(curr[1]+1,succ[1],num=distance[1])\n",
    "    z= np.linspace(curr[2]+1,succ[2],num=distance[2])\n",
    "    x1= np.full((distance[0]), curr[0])\n",
    "    y1= np.full((distance[1]), curr[1])\n",
    "    z1= np.full((distance[2]), curr[1])\n",
    "    print(x,y,z,x1,y1,z1)\n",
    "    return errs(x,y,z,x1,y1,z1,childs)\n",
    "\n",
    "def find_neigh(every,data_arr):\n",
    "    nb=[]\n",
    "    for j in range(data_arr.shape[0]):\n",
    "        if checkconnection(data_arr[every],data_arr[j]):\n",
    "            nb.append(j)\n",
    "    return nb\n",
    "\n",
    "def midpoint(p1, p2):\n",
    "    return np.asarray([(p1[0]+p2[0])/2, (p1[1]+p2[1])/2,(p1[2]+p2[2])/2])\n",
    "def cal_dist(a, b):\n",
    "    #print(a,b)\n",
    "    return  np.linalg.norm(a-b)\n",
    "\n",
    "def get_distance(a,b):\n",
    "\n",
    "    a,b= np.asarray([a]),np.asarray([b])\n",
    "    #print(a,b)\n",
    "    return cdist(a,b, metric='cityblock')\n",
    "\n",
    "\n",
    "def save_as_csv(D_graph,file_path,mode,waypts):\n",
    "    '''\n",
    "    mode=1 for save data\n",
    "    mode=2 for saving nodes \n",
    "    '''\n",
    "    if mode==1:\n",
    "        arr=[]\n",
    "        for key,vals in D_graph.items():\n",
    "            for subs,values in vals.items():\n",
    "                if subs!='nodes':\n",
    "                    for i in values:\n",
    "                        arr.append(i)\n",
    "        arr= np.asarray(arr)\n",
    "\n",
    "        one_ar= np.ones(arr.shape[0])\n",
    "\n",
    "        fine_arr= np.hstack((arr,one_ar[np.newaxis].T))\n",
    "\n",
    "        dfempty = pd.DataFrame({'Column1': fine_arr[:, 0], 'Column2': fine_arr[:, 1],\n",
    "                                'Column3': fine_arr[:, 2],'Column4': fine_arr[:, 3]})\n",
    "        dfempty.to_csv(file_path)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    if mode==2:\n",
    "        arr=[]\n",
    "        for key,vals in D_graph.items():\n",
    "            for subs,values in vals.items():\n",
    "                if subs=='nodes':\n",
    "                    for i in values:\n",
    "                        arr.append(i)\n",
    "        arr= np.asarray(arr)\n",
    "\n",
    "        one_ar= np.ones(arr.shape[0])\n",
    "\n",
    "        fine_arr= np.hstack((arr,one_ar[np.newaxis].T))\n",
    "\n",
    "        dfempty = pd.DataFrame({'Column1': fine_arr[:, 0], 'Column2': fine_arr[:, 1],\n",
    "                                'Column3': fine_arr[:, 2],'Column4': fine_arr[:, 3]})\n",
    "        dfempty.to_csv(file_path)\n",
    "        return True\n",
    "    \n",
    "    if mode==3:\n",
    "        arr=np.asarray(waypoints)\n",
    "        one_ar= np.ones(arr.shape[0])\n",
    "\n",
    "        fine_arr= np.hstack((arr,one_ar[np.newaxis].T))\n",
    "\n",
    "        dfempty = pd.DataFrame({'Column1': fine_arr[:, 0], 'Column2': fine_arr[:, 1],\n",
    "                                'Column3': fine_arr[:, 2],'Column4': fine_arr[:, 3]})\n",
    "        dfempty.to_csv(file_path)\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "def euc_dis(a,b):\n",
    "    a,b= np.asarray([a]),np.asarray([b])\n",
    "    return euclidean(a,b)\n",
    "\n",
    "def find_path_lenth(waypts):\n",
    "    length=0\n",
    "    for i in range(len(waypts)-1):\n",
    "        length += euc_dis(waypts[i],waypts[i+1])\n",
    "    return length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d74ca",
   "metadata": {},
   "source": [
    "## Learning Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9beda555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gyk/anaconda3/envs/rnd/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "occupied,empty = tree.extractPointCloud()\n",
    "#print(tree.getMetricSize())\n",
    "start_point= [0.0,0.0,0.0]\n",
    "max_size= [64., 51., 12.] #[64,51,10]#[22., 46., 36.] \n",
    "centers_arr=np.asarray([np.arange(int(start_point[0]+1),int(max_size[0]),8),\n",
    "         np.arange(int(start_point[1]+1),int(max_size[1]),8),\n",
    "         np.arange(int(start_point[2]+1),int(max_size[2]),8)])\n",
    "center_coords=[]\n",
    "for x in centers_arr[0]:\n",
    "    for y in centers_arr[1]:\n",
    "        for z in centers_arr[2]:\n",
    "            center_coords.append([x,y,z])  \n",
    "#print(center_coords)\n",
    "bbx_arr=np.asarray(center_coords,dtype='double')\n",
    "# fig = plt.figure(figsize=(20,20))\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "# ax.scatter(bbx_arr[:,0],bbx_arr[:,1],bbx_arr[:,2])\n",
    "# ax.scatter(occupied[:,0],occupied[:,1],occupied[:,2])\n",
    "# #ax.scatter(empty[:,0],empty[:,1],empty[:,2])\n",
    "# ax.set_xlabel('X ')\n",
    "# ax.set_ylabel('Y ')\n",
    "# ax.set_zlabel('Z ')\n",
    "# plt.show()\n",
    "\n",
    "err=[]\n",
    "for i in range(len(bbx_arr)):\n",
    "    try:\n",
    "        node=tree.search(bbx_arr[i])\n",
    "        #print(node.getValue())\n",
    "    except:\n",
    "        err.append(i)\n",
    "        #node.childExists(np.asarray(i,dtype='double'))\n",
    "\n",
    "# for i in err:\n",
    "#     print('fff',tree.getNodeChild())\n",
    "# curnode= tree.search(err[1])\n",
    "# print(curnode.hasChildren())\n",
    "# for i in tree.begin_tree():\n",
    "#     if i==curnode:\n",
    "#         print(i.getOccupancy())\n",
    "#plotin3d(np.asarray(err))\n",
    "bbx_arr_cleaned=[]\n",
    "for i in range(len(bbx_arr)):\n",
    "    if i not in err:\n",
    "        bbx_arr_cleaned.append(bbx_arr[i])\n",
    "bbx_arr_cleaned = np.asarray(bbx_arr_cleaned)\n",
    "#print(bbx_arr_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8bab0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17548"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8e13a7",
   "metadata": {},
   "source": [
    "### Get free voxels inside each bounding box \n",
    "\n",
    "#### Stucture = dict(0:dict('nodes':[],'(sam_node_1,sam_node_2)':[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da0630e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111])\n"
     ]
    }
   ],
   "source": [
    "graph={}\n",
    "box_size=8\n",
    "count=0\n",
    "number=5\n",
    "\n",
    "# free_nodes=[]\n",
    "# for i in tree.begin_leafs():\n",
    "#     if i.getOccupancy()< 0.5:\n",
    "#         #free_nodes.append({'pos':tuple(i.getCoordinate()),'size':i.getSize()})\n",
    "#         free_nodes.append(i.getCoordinate())\n",
    "# empty=np.asarray(free_nodes)\n",
    "one_ar= np.ones(empty.shape[0])\n",
    "\n",
    "fine_arr= np.hstack((empty,one_ar[np.newaxis].T))\n",
    "\n",
    "for idx,every in enumerate(bbx_arr_cleaned):\n",
    "    bbmin,bbmax= getbbminmax(every,box_size)\n",
    "    #print(count)\n",
    "    count=0\n",
    "    out=[]\n",
    "    for i in fine_arr:\n",
    "        if b_cond(bbmin,bbmax,i):\n",
    "            out.append(i)\n",
    "    graph[idx]=out\n",
    "\n",
    "print(graph.keys())      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3fce3b8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "32\n",
      "109\n",
      "65\n",
      "280\n",
      "10\n",
      "283\n",
      "0\n",
      "236\n",
      "0\n",
      "184\n",
      "0\n",
      "31\n",
      "6\n",
      "15\n",
      "143\n",
      "400\n",
      "108\n",
      "453\n",
      "15\n",
      "439\n",
      "0\n",
      "389\n",
      "0\n",
      "313\n",
      "0\n",
      "88\n",
      "94\n",
      "216\n",
      "166\n",
      "447\n",
      "102\n",
      "462\n",
      "19\n",
      "472\n",
      "0\n",
      "388\n",
      "0\n",
      "338\n",
      "0\n",
      "150\n",
      "149\n",
      "280\n",
      "171\n",
      "449\n",
      "100\n",
      "443\n",
      "23\n",
      "451\n",
      "0\n",
      "416\n",
      "0\n",
      "343\n",
      "0\n",
      "206\n",
      "130\n",
      "238\n",
      "193\n",
      "451\n",
      "125\n",
      "455\n",
      "36\n",
      "453\n",
      "0\n",
      "416\n",
      "0\n",
      "361\n",
      "0\n",
      "71\n",
      "58\n",
      "103\n",
      "214\n",
      "449\n",
      "154\n",
      "448\n",
      "53\n",
      "451\n",
      "2\n",
      "450\n",
      "0\n",
      "156\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "175\n",
      "348\n",
      "171\n",
      "448\n",
      "117\n",
      "451\n",
      "21\n",
      "228\n",
      "0\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "75\n",
      "139\n",
      "216\n",
      "458\n",
      "96\n",
      "239\n",
      "1\n",
      "8\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "59.41425395011902\n"
     ]
    }
   ],
   "source": [
    "stime= time.time()\n",
    "D_graph={}\n",
    "und_graph = nx.Graph()\n",
    "nodes_arr=[]\n",
    "count=0\n",
    "no_dic={}\n",
    "for keys,childs in graph.items():\n",
    "    #boundingbox idx (keys)\n",
    "    #print(keys,childs)\n",
    "    length= int(len(childs)*0.14)\n",
    "#     if length==1:\n",
    "#         print(childs)\n",
    "#         D_graph[keys]=childs\n",
    "#     else:\n",
    "    print(len(childs))\n",
    "    try:\n",
    "        data_arr=np.asarray(childs)\n",
    "        data_arr=data_arr[:,0:3]\n",
    "        G= nx.DiGraph()\n",
    "        for every in range(data_arr.shape[0]):\n",
    "            G.add_node(every)\n",
    "\n",
    "        for every in range(data_arr.shape[0]):\n",
    "            nb_vals=find_neigh(every,data_arr)\n",
    "            for j in nb_vals:\n",
    "                G.add_edge(every,j)\n",
    "\n",
    "        while True:\n",
    "            loc_path={}\n",
    "            nodes=getrandomvoxels(range(0,len(childs)),3)\n",
    "            loc_path['nodes']=[data_arr[x] for x in range(0,len(childs)) if x in nodes]\n",
    "            for subset in itertools.combinations(nodes,2):\n",
    "                try:\n",
    "                    path=list(nx.shortest_path(G,subset[0],subset[1]))\n",
    "                    node_a=list(data_arr[subset[0]])\n",
    "                    node_b=list(data_arr[subset[1]])\n",
    "                    if node_a not in nodes_arr:\n",
    "                        nodes_arr.append(node_a)\n",
    "                    if node_b not in nodes_arr:\n",
    "                        nodes_arr.append(node_b)\n",
    "                    idx_a,idx_b= nodes_arr.index(node_a),nodes_arr.index(node_b)\n",
    "                    #print(idx_a)\n",
    "                    pathlist=[]\n",
    "                    for i in path:\n",
    "                        pathlist.append(data_arr[i])\n",
    "                    loc_path[(idx_a,idx_b)]=pathlist\n",
    "                    #und_graph.add_edge(idx_a,idx_b,weight=cdist([node_a],[node_b], metric='cityblock'))\n",
    "                    comb_status= True\n",
    "                except:\n",
    "                    comb_status= False\n",
    "\n",
    "            if comb_status:\n",
    "                break\n",
    "\n",
    "    #     loc_path={}\n",
    "    #     nodes=getrandomvoxels(range(0,len(childs)),3)\n",
    "    #     loc_path['nodes']=[data_arr[x] for x in range(0,len(childs)) if x in nodes]\n",
    "    #     for subset in itertools.combinations(nodes,2):\n",
    "    #         try:\n",
    "    #             path=list(nx.shortest_path(G,subset[0],subset[1]))\n",
    "    #             pathlist=[]\n",
    "    #             for i in path:\n",
    "    #                 pathlist.append(data_arr[i])\n",
    "    #             loc_path[subset]=pathlist\n",
    "    #             comb_status= True\n",
    "    #         except:\n",
    "    #             print(subset)\n",
    "\n",
    "    #     print('done')   \n",
    "        D_graph[keys]= loc_path\n",
    "    except:\n",
    "        continue\n",
    "#print(D_graph)\n",
    "#########################################################################################\n",
    "centers_arr= {}\n",
    "for i in range(bbx_arr_cleaned.shape[0]):\n",
    "    for j in range(bbx_arr_cleaned.shape[0]):\n",
    "        dist=cal_dist(bbx_arr_cleaned[i,:],bbx_arr_cleaned[j,:])\n",
    "        #print(dist)\n",
    "        if i!=j and dist==8:\n",
    "            centers_arr[i,j]= midpoint(bbx_arr_cleaned[i,:],bbx_arr_cleaned[j,:])\n",
    "result = {}\n",
    "temp_arr= deepcopy(centers_arr)\n",
    "\n",
    "for key,value in temp_arr.items():\n",
    "        temp_arr[key] = list(value)\n",
    "for key,value in temp_arr.items():\n",
    "    if value not in result.values():\n",
    "        result[key] = value\n",
    "# print(result)\n",
    "##########################################################################################\n",
    "graph={}\n",
    "box_size=8\n",
    "count=0\n",
    "number=5\n",
    "\n",
    "one_ar= np.ones(empty.shape[0])\n",
    "\n",
    "fine_arr= np.hstack((empty,one_ar[np.newaxis].T))\n",
    "\n",
    "for idx,every in result.items():\n",
    "    bbmin,bbmax= getbbminmax(np.asarray(every),box_size)\n",
    "    out=[]\n",
    "    for i in empty:\n",
    "        if b_cond(bbmin,bbmax,i):\n",
    "            out.append(list(i))\n",
    "    graph[idx]=out\n",
    "\n",
    "#print(graph) \n",
    "###########################################################################################\n",
    "arr=[]\n",
    "\n",
    "for key,vals in D_graph.items():\n",
    "    for subs,values in vals.items():\n",
    "        if subs=='nodes':\n",
    "            for i in values:\n",
    "                arr.append(list(i))\n",
    "#arr= np.asarray(arr)\n",
    "#print(arr)\n",
    "\n",
    "for key,vals in graph.items():\n",
    "    comm_nodes=[]\n",
    "    for i in arr:\n",
    "        if i in vals:\n",
    "            comm_nodes.append(vals.index(i))\n",
    "    \n",
    "    data_arr=np.asarray(vals)\n",
    "    G= nx.DiGraph()\n",
    "    for every in range(data_arr.shape[0]):\n",
    "        G.add_node(every)\n",
    "       \n",
    "    for every in range(data_arr.shape[0]):\n",
    "        nb_vals=find_neigh(every,data_arr)\n",
    "        for j in nb_vals:\n",
    "            G.add_edge(every,j)\n",
    "    \n",
    "    loc_path={}\n",
    "    nodes=comm_nodes\n",
    "    #loc_path['nodes']=[data_arr[x] for x in range(0,len(childs)) if x in nodes]\n",
    "    for subset in itertools.combinations(nodes,2):\n",
    "        try:\n",
    "            path=list(nx.shortest_path(G,subset[0],subset[1]))\n",
    "            node_a=list(data_arr[subset[0]])\n",
    "            node_b=list(data_arr[subset[1]])\n",
    "            idx_a,idx_b= nodes_arr.index(node_a),nodes_arr.index(node_b)\n",
    "            pathlist=[]\n",
    "            for i in path:\n",
    "                pathlist.append(data_arr[i])\n",
    "            loc_path[(idx_a,idx_b)]=pathlist\n",
    "        except:\n",
    "            pass\n",
    "    D_graph[key]= loc_path\n",
    "time_learn= np.asarray(time.time()-stime)\n",
    "print(time_learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcdfe77",
   "metadata": {},
   "source": [
    "## Visualize Local paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06f0879e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_as_csv(D_graph,'/home/gyk/data/mypaths_empty_map2.csv',2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0606f44b",
   "metadata": {},
   "source": [
    "## Visualize nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f2e6757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_as_csv(D_graph,'/home/gyk/data/mypaths_nodes_map2.csv',1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732e1be8",
   "metadata": {},
   "source": [
    "## Create Graph and find path  PRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c01c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "und_graph = nx.Graph()\n",
    "for key,vals in D_graph.items():\n",
    "    for subs,values in vals.items():\n",
    "        if subs =='nodes':\n",
    "            pass\n",
    "        else:\n",
    "#             print(subs[0])\n",
    "            und_graph.add_edge(subs[0],subs[1],weight=get_distance(nodes_arr[subs[0]],nodes_arr[subs[1]]))\n",
    "df_out= pd.DataFrame(columns=['sx','sy','sz','ex','ey','ez','time_learn','time_query','pathlength'])\n",
    "\n",
    "# nx.draw(und_graph)\n",
    "# plt.show()\n",
    "# node_names=list(und_graph.nodes())\n",
    "# print(node_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9317a7d7",
   "metadata": {},
   "source": [
    "# Evaluation PRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c91a107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.5, 6.5, 4.5] [47.5, 32.5, 9.5]\n",
      "0.033000946044921875\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    gr_arr=[]\n",
    "    vals_dic={}\n",
    "    for key,vals in D_graph.items():\n",
    "        for subs,values in vals.items():\n",
    "            if subs=='nodes':\n",
    "                for i in values:\n",
    "                    gr_arr.append(i)\n",
    "\n",
    "    for key,vals in D_graph.items():\n",
    "        for subs,values in vals.items():\n",
    "            if subs!='nodes':\n",
    "                vals_dic[subs]=values\n",
    "\n",
    "    stime= time.time()\n",
    "    und_graph = nx.Graph()\n",
    "    for key,vals in D_graph.items():\n",
    "        for subs,values in vals.items():\n",
    "            if subs =='nodes':\n",
    "                pass\n",
    "            else:\n",
    "                und_graph.add_edge(subs[0],subs[1],weight=get_distance(nodes_arr[subs[0]],nodes_arr[subs[1]]))\n",
    "\n",
    "    start,stop= random.sample(nodes_arr,2)\n",
    "    \n",
    "    ## Give start and stop coordinates\n",
    "    \n",
    "    start= [8,8,3]\n",
    "    stop= [49,33,10]\n",
    "\n",
    "\n",
    "    dis_start=[]\n",
    "    dis_stop=[]\n",
    "    count=0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            for i in nodes_arr:\n",
    "                dis_start.append(euc_dis(start,i))\n",
    "                dis_stop.append(euc_dis(stop,i))\n",
    "            dis_s= deepcopy(dis_start)\n",
    "            dis_e= deepcopy(dis_stop)\n",
    "            dis_start.sort(),dis_stop.sort()\n",
    "\n",
    "            begin= dis_s.index(dis_start[count])\n",
    "            end=dis_e.index(dis_stop[count+1])\n",
    "\n",
    "            print(nodes_arr[begin],nodes_arr[end])\n",
    "            #print(und_graph.nodes)\n",
    "            shor_path=nx.shortest_path(und_graph,begin,end)\n",
    "            comb_status= True\n",
    "        except:\n",
    "            count+=1\n",
    "            #print(count)\n",
    "            if count>1000:\n",
    "                comb_status= True\n",
    "            comb_status= False\n",
    "\n",
    "        if comb_status:\n",
    "            break\n",
    "\n",
    "\n",
    "    waypoints=[]\n",
    "    for elem in range(0,len(shor_path)-1):\n",
    "        try:\n",
    "            temp=vals_dic[(shor_path[elem],shor_path[elem+1])]\n",
    "            for i in temp:\n",
    "                waypoints.append(i)\n",
    "        except:\n",
    "            temp=vals_dic[(shor_path[elem+1],shor_path[elem])]\n",
    "            for i in temp:\n",
    "                waypoints.append(i)\n",
    "    # print(waypoints)\n",
    "    time_query= np.asarray(time.time()-stime)\n",
    "    print(time_query)\n",
    "    pathlength=np.asarray(find_path_lenth(waypoints))\n",
    "\n",
    "    pos=(np.hstack((nodes_arr[begin],nodes_arr[end],time_learn,time_query,pathlength)))\n",
    "    #print(pos)\n",
    "    df_temp=pd.DataFrame([pos],columns=['sx','sy','sz','ex','ey','ez','time_learn','time_query','pathlength'])\n",
    "    df_out= df_out.append(df_temp,ignore_index=True)\n",
    "\n",
    "waypoints.append([23.5 , 21.5 , 10.5])\n",
    "waypoints=np.asarray(waypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0205253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sx    sy   sz    ex    ey   ez  time_learn  time_query  pathlength\n",
      "0  4.0  10.0  3.0   4.0  12.0  4.0   59.414254    0.042303    3.000000\n",
      "1  8.5   6.5  4.5  47.5  32.5  9.5   59.414254    0.033001  128.468152\n"
     ]
    }
   ],
   "source": [
    "print(df_out.head())\n",
    "df_out.to_csv('/home/gyk/data/prm/evaluationubigmap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "187b2b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_as_csv(4,'/home/gyk/data/prm/mypaths_path_prm_{}.csv'.format(6),3,waypoints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
